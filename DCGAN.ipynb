{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pokeymon GAN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM0oDh/psyrgwha42JWa7Vh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4c25e96bcb6e46dd810bc4db9db05e0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_76b82fe0854f42f489a8797725f3ad7b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_02793db8b41a4ac0993cafbb672f9afc","IPY_MODEL_d4f0df16bc8b40b2bc3b64c36de12545"]}},"76b82fe0854f42f489a8797725f3ad7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"02793db8b41a4ac0993cafbb672f9afc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3f87dc09bcca43e7991f3c4ebce6b4e6","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":100,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a2fc24d4c0394f5383881eb0e7016a30"}},"d4f0df16bc8b40b2bc3b64c36de12545":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e2506f90012b438f8fd6e8bad4b9a476","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 100/100 [00:30&lt;00:00,  3.28it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d9f784085c304c978f9af82facc11c7d"}},"3f87dc09bcca43e7991f3c4ebce6b4e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a2fc24d4c0394f5383881eb0e7016a30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e2506f90012b438f8fd6e8bad4b9a476":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d9f784085c304c978f9af82facc11c7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"255c0f9963744d5c845878b591ebc6d1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_45c0a9251a1e476c9beda21743cf881e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fc40be838f6241ef9d478b1e42722b5d","IPY_MODEL_a4d972666b5c43f3a2149bdeb2b99165"]}},"45c0a9251a1e476c9beda21743cf881e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fc40be838f6241ef9d478b1e42722b5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d31c2f3019864008bb108df02b3eba12","_dom_classes":[],"description":" 51%","_model_name":"FloatProgressModel","bar_style":"danger","max":30000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":15310,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1904bd503600482096d52e55327c8895"}},"a4d972666b5c43f3a2149bdeb2b99165":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3494690274a24ba2b70220994d6da96a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 15310/30000 [2:43:32&lt;2:34:13,  1.59it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1a859ad7f5a54aabb04583919f78d058"}},"d31c2f3019864008bb108df02b3eba12":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1904bd503600482096d52e55327c8895":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3494690274a24ba2b70220994d6da96a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1a859ad7f5a54aabb04583919f78d058":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"wn4YCv1sWQnA","executionInfo":{"status":"ok","timestamp":1602587215725,"user_tz":-330,"elapsed":1161,"user":{"displayName":"TE_COMP_A_09 Devavrat Singh Bisht","photoUrl":"","userId":"18417288358959782080"}},"outputId":"8937410a-c4e9-4c62-e91c-1eeffa98730c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yuJGZoNFZ4Uz","executionInfo":{"status":"ok","timestamp":1602587220121,"user_tz":-330,"elapsed":3331,"user":{"displayName":"TE_COMP_A_09 Devavrat Singh Bisht","photoUrl":"","userId":"18417288358959782080"}},"outputId":"27005183-5ca5-4d17-992e-a1229330d730","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","tf.device(device_name)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.eager.context._EagerDeviceContext at 0x7f00c1bc2278>"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"r2FGrasAGpuW","executionInfo":{"status":"ok","timestamp":1602587221619,"user_tz":-330,"elapsed":918,"user":{"displayName":"TE_COMP_A_09 Devavrat Singh Bisht","photoUrl":"","userId":"18417288358959782080"}}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Input, Flatten, Conv2D, Dense, Dropout, Reshape, Conv2DTranspose\n","from keras.models import Model\n","from keras.utils.vis_utils import plot_model"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"CIkOcZF4bjd0","executionInfo":{"status":"ok","timestamp":1602587222975,"user_tz":-330,"elapsed":745,"user":{"displayName":"TE_COMP_A_09 Devavrat Singh Bisht","photoUrl":"","userId":"18417288358959782080"}}},"source":["from __future__ import print_function, division\n","\n","from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"u4KoNoOGc4hb","executionInfo":{"status":"ok","timestamp":1602587224580,"user_tz":-330,"elapsed":1165,"user":{"displayName":"TE_COMP_A_09 Devavrat Singh Bisht","photoUrl":"","userId":"18417288358959782080"}}},"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","import cv2\n","import random\n","import scipy.misc\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from tqdm.notebook import tqdm\n","import cv2"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"NZ0XnE3_khF_","executionInfo":{"status":"ok","timestamp":1602587225944,"user_tz":-330,"elapsed":921,"user":{"displayName":"TE_COMP_A_09 Devavrat Singh Bisht","photoUrl":"","userId":"18417288358959782080"}}},"source":["#import data\n","data_path = \"/content/drive/My Drive/Study/DL/GAN/data/\"\n","output_path = \"/content/drive/My Drive/Study/DL/GAN/output/\"\n","img_list = os.listdir(data_path)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"xcPISCEEi5n7","executionInfo":{"status":"ok","timestamp":1602587273199,"user_tz":-330,"elapsed":3017,"user":{"displayName":"TE_COMP_A_09 Devavrat Singh Bisht","photoUrl":"","userId":"18417288358959782080"}},"outputId":"515bf5ec-afa4-445c-d3d2-fb99206b489b","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["4c25e96bcb6e46dd810bc4db9db05e0c","76b82fe0854f42f489a8797725f3ad7b","02793db8b41a4ac0993cafbb672f9afc","d4f0df16bc8b40b2bc3b64c36de12545","3f87dc09bcca43e7991f3c4ebce6b4e6","a2fc24d4c0394f5383881eb0e7016a30","e2506f90012b438f8fd6e8bad4b9a476","d9f784085c304c978f9af82facc11c7d"]}},"source":["def load_data():\n","  # load image as pixel array\n","  data = []\n","  for i in tqdm(img_list):\n","    img = cv2.imread(data_path + i)\n","    img = cv2.resize(img, (128, 128))\n","    img = list(img)\n","    data.append(img)\n","\n","  return np.array(data)\n","\n","X_train = load_data()"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c25e96bcb6e46dd810bc4db9db05e0c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zfsxirayQQIP","executionInfo":{"status":"ok","timestamp":1602591395584,"user_tz":-330,"elapsed":1216,"user":{"displayName":"TE_COMP_A_09 Devavrat Singh Bisht","photoUrl":"","userId":"18417288358959782080"}}},"source":["class GAN():\n","  def __init__(self, X_train):\n","\n","    self.X_train = X_train\n","    self.img_rows, self.img_cols, self.channels = self.X_train.shape[1:]\n","    self.img_shape = self.X_train.shape[1:]\n","    self.latent_dim = 100\n","\n","    self.noise_rows = 8\n","    self.noise_cols = 8\n","    self.noise_channels = 3\n","\n","    optimizer = Adam(0.0002, 0.5)\n","\n","    # Build and compile the discriminator\n","    self.discriminator = self.build_discriminator()\n","    self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","\n","    # Build the generator\n","    self.generator = self.build_generator()\n","\n","    # The generator takes noise as input and generates imgs\n","    z = Input(shape=(self.latent_dim,))\n","    img = self.generator(z)\n","\n","    # For the combined model we will only train the generator\n","    self.discriminator.trainable = False\n","\n","    # The discriminator takes generated images as input and determines validity\n","    validity = self.discriminator(img)\n","\n","    # The combined model  (stacked generator and discriminator)\n","    # Trains the generator to fool the discriminator\n","    self.combined = Model(z, validity)\n","    self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n","\n","    self.g_loss = []\n","    self.d_loss = []\n","\n","  def build_generator(self):\n","\n","    model = Sequential()\n","\n","    model.add(Dense(self.noise_rows*self.noise_cols*self.noise_channels, activation='relu'))\n","    model.add(Reshape((self.noise_rows, self.noise_cols, self.noise_channels)))\n","    model.add(Conv2DTranspose(filters=512, kernel_size=[5, 5], strides=[2, 2], padding=\"same\", activation='relu'))\n","    model.add(Conv2DTranspose(filters=256, kernel_size=[5, 5], strides=[2, 2], padding=\"same\", activation='relu'))\n","    model.add(Conv2DTranspose(filters=128, kernel_size=[5, 5], strides=[2, 2], padding=\"same\", activation='relu'))\n","    model.add(Conv2DTranspose(filters=self.channels, kernel_size=[5, 5], strides=[2, 2], padding=\"same\",activation='relu'))\n","\n","    noise = Input(shape=(self.latent_dim,))\n","    img = model(noise)\n","\n","    return Model(noise, img)\n","\n","\n","  def build_discriminator(self):\n","\n","    model = Sequential()\n","\n","    model.add(Conv2D(filters=64, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\", kernel_initializer='glorot_uniform' ,activation='relu'))\n","    model.add(Conv2D(filters=128, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\", activation='relu'))\n","    model.add(Conv2D(filters=256, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\", activation='relu'))\n","    model.add(Conv2D(filters=512, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\", activation='relu'))\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    img = Input(shape=self.img_shape)\n","    validity = model(img)\n","\n","    return Model(img, validity)\n","\n","\n","\n","  def train(self, epochs, batch_size=128, sample_interval=50):\n","\n","    # Load the dataset\n","    X_train = self.X_train\n","\n","    # Rescale 0 to 1\n","    X_train = X_train / 255\n","    #X_train = np.expand_dims(X_train, axis=3)\n","\n","    # Adversarial ground truths\n","    valid = np.ones((batch_size, 1))\n","    fake = np.zeros((batch_size, 1))\n","\n","    for epoch in tqdm(range(epochs)):\n","\n","      # ---------------------\n","      #  Train Discriminator\n","      # ---------------------\n","\n","      # Select a random batch of images\n","      idx = np.random.randint(0, X_train.shape[0], batch_size)\n","      imgs = X_train[idx]\n","\n","      noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","\n","      # Generate a batch of new images\n","      gen_imgs = self.generator.predict(noise)\n","\n","      # Train the discriminator\n","      d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n","      d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n","      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","      self.d_loss.append(d_loss)\n","\n","      # ---------------------\n","      #  Train Generator\n","      # ---------------------\n","\n","      noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","\n","      # Train the generator (to have the discriminator label samples as valid)\n","      g_loss = self.combined.train_on_batch(noise, valid)\n","      self.g_loss.append(g_loss)\n","\n","      # If at save interval => save generated image samples and Plot the progress\n","      if epoch % sample_interval == 0:\n","        self.sample_images(epoch)\n","        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n","\n","  \n","\n","  def sample_images(self, epoch):\n","        r, c = 5, 5\n","        noise = np.random.normal(0, 1, (r * c, self.latent_dim)) #generating r*c random noise samples\n","        gen_imgs = self.generator.predict(noise)\n","\n","\n","        #clipping the output to range [0, 1 ]\n","        np.clip(gen_imgs, 0, 1, out=gen_imgs)\n","\n","\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i,j].imshow(gen_imgs[cnt])\n","                axs[i,j].axis('off')\n","                cnt += 1\n","\n","        fig = plt.gcf()\n","        fig.set_size_inches(18, 18)\n","        fig.tight_layout()\n","        fig.savefig(output_path + \"%d.png\" % epoch)\n","        plt.close()"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"MR7sGgNpd-Iv","executionInfo":{"status":"error","timestamp":1602601217915,"user_tz":-330,"elapsed":9819893,"user":{"displayName":"TE_COMP_A_09 Devavrat Singh Bisht","photoUrl":"","userId":"18417288358959782080"}},"outputId":"81f055f5-8227-4dca-de20-525c5ff99e53","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["255c0f9963744d5c845878b591ebc6d1","45c0a9251a1e476c9beda21743cf881e","fc40be838f6241ef9d478b1e42722b5d","a4d972666b5c43f3a2149bdeb2b99165","d31c2f3019864008bb108df02b3eba12","1904bd503600482096d52e55327c8895","3494690274a24ba2b70220994d6da96a","1a859ad7f5a54aabb04583919f78d058"]}},"source":["if __name__ == '__main__':\n","    gan = GAN(X_train)\n","    gan.train(epochs=30000, batch_size=32, sample_interval=200)"],"execution_count":51,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"255c0f9963744d5c845878b591ebc6d1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=30000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["0 [D loss: 0.703272, acc.: 0.00%] [G loss: 0.692785]\n","200 [D loss: 0.000326, acc.: 100.00%] [G loss: 7.430267]\n","400 [D loss: 0.187056, acc.: 96.88%] [G loss: 2.702280]\n","600 [D loss: 0.556788, acc.: 67.19%] [G loss: 1.302315]\n","800 [D loss: 0.649593, acc.: 57.81%] [G loss: 2.734946]\n","1000 [D loss: 0.163179, acc.: 95.31%] [G loss: 2.905136]\n","1200 [D loss: 0.517689, acc.: 76.56%] [G loss: 1.330114]\n","1400 [D loss: 0.255898, acc.: 98.44%] [G loss: 1.928577]\n","1600 [D loss: 0.157979, acc.: 96.88%] [G loss: 2.761956]\n","1800 [D loss: 0.161223, acc.: 100.00%] [G loss: 2.038683]\n","2000 [D loss: 1.717680, acc.: 35.94%] [G loss: 3.707345]\n","2200 [D loss: 0.052008, acc.: 98.44%] [G loss: 3.615581]\n","2400 [D loss: 0.116154, acc.: 96.88%] [G loss: 3.331873]\n","2600 [D loss: 0.558298, acc.: 76.56%] [G loss: 1.495312]\n","2800 [D loss: 0.187989, acc.: 92.19%] [G loss: 5.380606]\n","3000 [D loss: 0.065275, acc.: 98.44%] [G loss: 4.241436]\n","3200 [D loss: 0.041566, acc.: 100.00%] [G loss: 3.874578]\n","3400 [D loss: 0.224641, acc.: 98.44%] [G loss: 2.579537]\n","3600 [D loss: 0.029681, acc.: 100.00%] [G loss: 4.661294]\n","3800 [D loss: 0.000261, acc.: 100.00%] [G loss: 7.688775]\n","4000 [D loss: 0.002478, acc.: 100.00%] [G loss: 5.475194]\n","4200 [D loss: 0.016805, acc.: 100.00%] [G loss: 4.608416]\n","4400 [D loss: 0.005789, acc.: 100.00%] [G loss: 4.600932]\n","4600 [D loss: 0.000203, acc.: 100.00%] [G loss: 7.938885]\n","4800 [D loss: 0.000244, acc.: 100.00%] [G loss: 7.677438]\n","5000 [D loss: 0.039162, acc.: 100.00%] [G loss: 3.008118]\n","5200 [D loss: 0.032368, acc.: 100.00%] [G loss: 3.505903]\n","5400 [D loss: 0.673895, acc.: 56.25%] [G loss: 2.631269]\n","5600 [D loss: 0.677198, acc.: 59.38%] [G loss: 0.744687]\n","5800 [D loss: 0.715806, acc.: 50.00%] [G loss: 0.861127]\n","6000 [D loss: 0.093580, acc.: 96.88%] [G loss: 3.570384]\n","6200 [D loss: 0.241821, acc.: 98.44%] [G loss: 2.167907]\n","6400 [D loss: 0.208559, acc.: 93.75%] [G loss: 1.784399]\n","6600 [D loss: 0.078326, acc.: 98.44%] [G loss: 5.343464]\n","6800 [D loss: 0.136093, acc.: 96.88%] [G loss: 3.623899]\n","7000 [D loss: 0.183538, acc.: 95.31%] [G loss: 3.587270]\n","7200 [D loss: 0.007393, acc.: 100.00%] [G loss: 4.654739]\n","7400 [D loss: 0.051994, acc.: 98.44%] [G loss: 5.130296]\n","7600 [D loss: 0.177175, acc.: 92.19%] [G loss: 4.374353]\n","7800 [D loss: 0.052753, acc.: 98.44%] [G loss: 4.855236]\n","8000 [D loss: 0.003846, acc.: 100.00%] [G loss: 6.007674]\n","8200 [D loss: 0.009722, acc.: 100.00%] [G loss: 5.379981]\n","8400 [D loss: 0.415666, acc.: 76.56%] [G loss: 1.960125]\n","8600 [D loss: 0.254727, acc.: 92.19%] [G loss: 2.496512]\n","8800 [D loss: 0.000585, acc.: 100.00%] [G loss: 7.520151]\n","9000 [D loss: 0.188748, acc.: 96.88%] [G loss: 4.328780]\n","9200 [D loss: 0.006890, acc.: 100.00%] [G loss: 5.471738]\n","9400 [D loss: 0.004618, acc.: 100.00%] [G loss: 4.785841]\n","9600 [D loss: 0.004745, acc.: 100.00%] [G loss: 4.790705]\n","9800 [D loss: 0.092117, acc.: 98.44%] [G loss: 5.290292]\n","10000 [D loss: 0.004126, acc.: 100.00%] [G loss: 5.005212]\n","10200 [D loss: 0.001882, acc.: 100.00%] [G loss: 5.675128]\n","10400 [D loss: 0.004941, acc.: 100.00%] [G loss: 4.735471]\n","10600 [D loss: 0.081039, acc.: 98.44%] [G loss: 4.856555]\n","10800 [D loss: 0.005710, acc.: 100.00%] [G loss: 4.646226]\n","11000 [D loss: 0.005347, acc.: 100.00%] [G loss: 4.671450]\n","11200 [D loss: 0.078700, acc.: 98.44%] [G loss: 4.342069]\n","11400 [D loss: 0.003384, acc.: 100.00%] [G loss: 5.115633]\n","11600 [D loss: 0.002054, acc.: 100.00%] [G loss: 5.613829]\n","11800 [D loss: 0.074368, acc.: 98.44%] [G loss: 3.992072]\n","12000 [D loss: 0.000027, acc.: 100.00%] [G loss: 9.880748]\n","12200 [D loss: 0.065707, acc.: 98.44%] [G loss: 3.414108]\n","12400 [D loss: 0.165553, acc.: 93.75%] [G loss: 3.342782]\n","12600 [D loss: 0.003128, acc.: 100.00%] [G loss: 5.308289]\n","12800 [D loss: 0.002845, acc.: 100.00%] [G loss: 5.373108]\n","13000 [D loss: 0.002154, acc.: 100.00%] [G loss: 5.563994]\n","13200 [D loss: 0.071532, acc.: 98.44%] [G loss: 3.582547]\n","13400 [D loss: 0.018226, acc.: 100.00%] [G loss: 3.866398]\n","13600 [D loss: 0.144748, acc.: 96.88%] [G loss: 4.466005]\n","13800 [D loss: 0.004176, acc.: 100.00%] [G loss: 4.935684]\n","14000 [D loss: 0.003438, acc.: 100.00%] [G loss: 5.086251]\n","14200 [D loss: 0.005564, acc.: 100.00%] [G loss: 4.659670]\n","14400 [D loss: 0.075902, acc.: 98.44%] [G loss: 4.219479]\n","14600 [D loss: 0.148610, acc.: 96.88%] [G loss: 4.000824]\n","14800 [D loss: 0.007532, acc.: 100.00%] [G loss: 4.366742]\n","15000 [D loss: 0.002867, acc.: 100.00%] [G loss: 5.235852]\n","15200 [D loss: 0.001815, acc.: 100.00%] [G loss: 5.698802]\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-c4fbe707199a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-50-842e1e966541>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0;31m# Train the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m       \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1698\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1699\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1635\u001b[0m     \"\"\"\n\u001b[1;32m   1636\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m       \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m   def train_on_batch(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \"\"\"\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3574\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3575\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3576\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3577\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3578\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    858\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0;32m--> 860\u001b[0;31m           self.handle, value_tensor, name=name)\n\u001b[0m\u001b[1;32m    861\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[0;34m(resource, value, name)\u001b[0m\n\u001b[1;32m    142\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m    143\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AssignVariableOp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         tld.op_callbacks, resource, value)\n\u001b[0m\u001b[1;32m    145\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"3E8O4lzz4tWz"},"source":[""],"execution_count":null,"outputs":[]}]}